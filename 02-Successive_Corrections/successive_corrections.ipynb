{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c27f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created By    : Jared W. Marquis\n",
    "Creation Date : 01 August 2022\n",
    "Course        : ATSC 528 - Atmospheric Data Analysis\n",
    "Assignment    : #02 - Successive Corrections\n",
    "\n",
    "Purpose:\n",
    "Script to take sparse upper air observations and analyze them on a\n",
    "polar stereographic map projection using successive corrections.\n",
    "[PUT MORE INFORMATION HERE - I.E., WHAT SPECIFIC THING IS BEING DONE]\n",
    "\n",
    "\"\"\"\n",
    "__author__    = \"Jared W. Marquis\"\n",
    "__contact__   = \"jared.marquis@und.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7335135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Required Modules (shouldn't need to change) ###\n",
    "import numpy as np                 #numpy for math\n",
    "import matplotlib.pyplot as plt    #matplotlib for plotting\n",
    "import cartopy.crs as ccrs         #cartopy for plotting on map\n",
    "import cartopy.feature as cfeature #cartopy basic shapefiles\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc35da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create function for Cressman Analysis ###\n",
    "def cressman_weight(dik, R):\n",
    "    if dik > R:\n",
    "        return 0\n",
    "    else:\n",
    "        return (R**2 - dik**2) / (R**2 + dik**2)\n",
    "def cressman(xob, yob, zob, xg, yg, dmin, radius):\n",
    "    R = radius * dmin\n",
    "    analysis = np.zeros_like(xg)\n",
    "    for i in range(xg.shape[0]):\n",
    "        for j in range(xg.shape[1]):\n",
    "            denom = 0\n",
    "            weight_fork = 0\n",
    "            for x, y, z in zip(xob, yob, zob):\n",
    "                dik = np.sqrt((xg[i, j] - x)**2 + (yg[i, j] - y)**2)\n",
    "                weight = cressman_weight(dik, R)\n",
    "                weight_fork += weight * z\n",
    "                denom += weight\n",
    "            if denom > 0:\n",
    "                analysis[i, j] = weight_fork / denom\n",
    "            else:\n",
    "                analysis[i, j] = np.nan\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac991609",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create function for bilinear interpolation ###\n",
    "def bilinear_interpolate(xob, yob, xg, yg, analysis):\n",
    "    interpolated_vals = np.zeros(xob.shape)\n",
    "    for i in range(len(xob)):\n",
    "        ob_indy = (yob[i]-y0)/del_y\n",
    "        ob_indx = (xob[i]-x0)/del_x\n",
    "        if ob_indx > 21 or ob_indx < 0 or ob_indy > 27 or ob_indy < 0:\n",
    "            interpolated_vals[i] = 0\n",
    "        else:\n",
    "            bl_indy = np.floor(ob_indy).astype(int)\n",
    "            bl_indx = np.floor(ob_indx).astype(int)\n",
    "            br_indy = np.floor(ob_indy).astype(int)\n",
    "            br_indx = np.floor(bl_indx + 1).astype(int)\n",
    "            tl_indy = np.floor(bl_indy + 1).astype(int)\n",
    "            tl_indx = np.floor(ob_indx).astype(int)\n",
    "            tr_indy = np.floor(bl_indy + 1).astype(int)\n",
    "            tr_indx = np.floor(bl_indx + 1).astype(int)\n",
    "            left_value = analysis[bl_indy, bl_indx] + ((analysis[tl_indy, tl_indx] -  analysis[bl_indy, bl_indx]) / (tl_indy - bl_indy)) * (ob_indy - bl_indy)\n",
    "            right_value = analysis[br_indy, br_indx] + ((analysis[tr_indy, tr_indx] -  analysis[br_indy, br_indx]) / (tr_indy - br_indy)) * (ob_indy - br_indy)\n",
    "            bilinear_val = left_value + ((right_value - left_value) / 1) * (ob_indx - bl_indx)\n",
    "            interpolated_vals[i] = bilinear_val\n",
    "    return interpolated_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55bf048",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in observations ###\n",
    "AllData = np.loadtxt('RAOBs_201903131200.txt',dtype='str')\n",
    "\n",
    "Lat = np.ones((np.size(AllData)))*np.nan\n",
    "Lon = np.ones((np.size(AllData)))*np.nan\n",
    "GeoHeight = np.ones((np.size(AllData)))*np.nan\n",
    "WindDir = np.ones((np.size(AllData)))*np.nan\n",
    "WindSpd = np.ones((np.size(AllData)))*np.nan\n",
    "\n",
    "for i in range(0,np.size(AllData)):\n",
    "    Data = AllData[i].split(',')\n",
    "    Lat[i] = float(Data[1])\n",
    "    Lon[i] = float(Data[2])\n",
    "    GeoHeight[i] = float(Data[3])\n",
    "    WindDir[i] = float(Data[4])\n",
    "    WindSpd[i] = float(Data[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set up analysis map with a 22x28 rectangular grid of points ###\n",
    "x0 = 18.9\n",
    "y0 = -6.3\n",
    "del_x = 1.27\n",
    "del_y = 1.27\n",
    "x = x0 + np.arange(22) * del_x\n",
    "y = y0 + np.arange(28) * del_y\n",
    "xg, yg = np.meshgrid(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64629e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert obs lat/long to x,y ###\n",
    "rho = 6371\n",
    "lambda0 = -115\n",
    "lambda0_r = np.radians(lambda0)\n",
    "phi0 = 60\n",
    "phi0_r = np.radians(phi0)\n",
    "map_scale = 1/15000000\n",
    "\n",
    "Lat_r = np.radians(Lat)\n",
    "Lon_r = np.radians(Lon)\n",
    "\n",
    "xkm = rho * (((1 + np.sin(phi0_r))/(1 + np.sin(Lat_r))) * np.cos(Lat_r) * np.cos(Lon_r - lambda0_r))\n",
    "ykm = rho * (((1 + np.sin(phi0_r))/(1 + np.sin(Lat_r))) * np.cos(Lat_r) * np.sin(Lon_r - lambda0_r))\n",
    "\n",
    "xcm = xkm * 1E5\n",
    "ycm = ykm * 1E5\n",
    "\n",
    "xob = xcm * map_scale\n",
    "yob = ycm * map_scale\n",
    "\n",
    "yg_earth = yg / map_scale / 1E5\n",
    "xg_earth = xg / map_scale / 1E5\n",
    "\n",
    "Lat_g = np.degrees((np.pi/2) - 2*np.arctan( np.sqrt(xg_earth**2 + yg_earth**2) / (rho*(1+np.sin(phi0_r) ) )))\n",
    "Lon_g = lambda0 + np.degrees(np.arctan(yg_earth/xg_earth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5634ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perform 500mb geopotential height analyses using a Cressman weighting Function###\n",
    "#Use radii of influence 4, 2.5, 1.5 *dmin\n",
    "min_distances = []\n",
    "r1 = 4\n",
    "r2 = 2.5\n",
    "r3 = 1.5\n",
    "\n",
    "for i in range(len(xob)):\n",
    "    min_dist = np.inf\n",
    "    for j in range(len(yob)):\n",
    "        if i != j:\n",
    "            dxob = xob[i] - xob[j]  \n",
    "            dyob = yob[i] - yob[j]\n",
    "            dist = np.sqrt(dxob ** 2 + dyob ** 2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "    min_distances.append(min_dist)\n",
    "dmin = np.mean(min_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4450fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### First analysis, no successive corrections ##\n",
    "R = r1 * dmin\n",
    "first_pass = np.zeros_like(xg)\n",
    "for i in range(xg.shape[0]):\n",
    "    for j in range(xg.shape[1]):\n",
    "        denom = 0\n",
    "        weight_fork = 0\n",
    "        for x, y, z in zip(xob, yob, GeoHeight):\n",
    "            dik = np.sqrt((xg[i, j] - x)**2 + (yg[i, j] - y)**2)\n",
    "            weight = cressman_weight(dik, R)\n",
    "            weight_fork += weight * z\n",
    "            denom += weight\n",
    "        if denom > 0:\n",
    "            first_pass[i, j] = weight_fork / denom\n",
    "        else:\n",
    "            first_pass[i, j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next Analyses ###\n",
    "bilinear = bilinear_interpolate(xob, yob, xg, yg, first_pass)\n",
    "R1 = r1 * dmin\n",
    "first_analysis = np.zeros_like(xob)\n",
    "rev_cressman = np.zeros_like(xob)\n",
    "for i in range(xob.shape[0]):\n",
    "    second_denom = 0\n",
    "    weight_fark = 0\n",
    "    for j in range(xg.shape[0]):\n",
    "        for k in range(xg.shape[1]):\n",
    "            second_dik = np.sqrt((xob[i]-xg[j,k])**2+(yob[i]-yg[j,k])**2)\n",
    "            second_weight = cressman_weight(second_dik,R1)\n",
    "            weight_fark += second_weight*first_pass[j,k]\n",
    "            second_denom += second_weight\n",
    "        if second_denom > 0:\n",
    "            rev_cressman[i] = weight_fark/second_denom\n",
    "        else:\n",
    "            rev_cressman[i] = np.nan\n",
    "    if bilinear[i] > 0:\n",
    "        first_analysis[i] = bilinear[i]\n",
    "    else:\n",
    "        first_analysis[i] = rev_cressman[i]\n",
    "\n",
    "R2 = r2 * dmin\n",
    "second_pass = np.zeros_like(xg)\n",
    "for i in range(xg.shape[0]):\n",
    "    for j in range(xg.shape[1]):\n",
    "        sec_denom = 0\n",
    "        sec_weight_fork = 0\n",
    "        for x, y, o, a in zip(xob, yob, GeoHeight, first_analysis):\n",
    "            sec_dik = np.sqrt((xg[i, j] - x)**2 + (yg[i, j] - y)**2)\n",
    "            fork_fark =  o - a\n",
    "            sec_weight = cressman_weight(sec_dik, R2)\n",
    "            if math.isnan(fork_fark):\n",
    "                sec_weight_fork += 0\n",
    "            else:\n",
    "                sec_weight_fork += sec_weight*fork_fark\n",
    "            sec_denom += sec_weight\n",
    "        if sec_denom > 0:\n",
    "            second_pass[i, j] = first_pass[i, j] + (sec_weight_fork / sec_denom)\n",
    "        else:\n",
    "            second_pass[i, j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b5c9d-0bd5-4908-a462-bc7b6f776c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next Analyses ###\n",
    "bilinear2 = bilinear_interpolate(xob, yob, xg, yg, second_pass)\n",
    "R2 = r2 * dmin\n",
    "second_analysis = np.zeros_like(xob)\n",
    "rev_cressman2 = np.zeros_like(xob)\n",
    "for i in range(xob.shape[0]):\n",
    "    third_denom = 0\n",
    "    weight_fark2 = 0\n",
    "    for j in range(xg.shape[0]):\n",
    "        for k in range(xg.shape[1]):\n",
    "            third_dik = np.sqrt((xob[i]-xg[j,k])**2+(yob[i]-yg[j,k])**2)\n",
    "            third_weight = cressman_weight(third_dik,R2)\n",
    "            weight_fark2 += third_weight*second_pass[j,k]\n",
    "            third_denom += third_weight\n",
    "        if third_denom > 0:\n",
    "            rev_cressman2[i] = weight_fark2/third_denom\n",
    "        else:\n",
    "            rev_cressman2[i] = np.nan\n",
    "    if bilinear2[i] > 0:\n",
    "        second_analysis[i] = bilinear2[i]\n",
    "    else:\n",
    "        second_analysis[i] = rev_cressman2[i]\n",
    "        \n",
    "R3 = r3 * dmin\n",
    "third_pass = np.zeros_like(xg)\n",
    "for i in range(xg.shape[0]):\n",
    "    for j in range(xg.shape[1]):\n",
    "        thir_denom = 0\n",
    "        thir_weight_fork = 0\n",
    "        for x, y, o, a in zip(xob, yob, GeoHeight, second_analysis):\n",
    "            thir_dik = np.sqrt((xg[i, j] - x)**2 + (yg[i, j] - y)**2)\n",
    "            fork_fark2 =  o - a\n",
    "            thir_weight = cressman_weight(thir_dik, R3)\n",
    "            if math.isnan(fork_fark2):\n",
    "                thir_weight_fork += 0\n",
    "            else:\n",
    "                thir_weight_fork += thir_weight*fork_fark2\n",
    "            #print(sec_weight_sum)\n",
    "            #sec_weight_fork += sec_weight * fork_fark\n",
    "            thir_denom += thir_weight\n",
    "        if thir_denom > 0:\n",
    "            third_pass[i, j] = second_pass[i, j] + (thir_weight_fork / thir_denom)\n",
    "        else:\n",
    "            third_pass[i, j] = np.nan\n",
    "\n",
    "### Third analysis for RMS purposes\n",
    "bilinear3 = bilinear_interpolate(xob, yob, xg, yg, third_pass)\n",
    "R3 = r3 * dmin\n",
    "third_analysis = np.zeros_like(xob)\n",
    "rev_cressman3 = np.zeros_like(xob)\n",
    "for i in range(xob.shape[0]):\n",
    "    fourth_denom = 0\n",
    "    weight_fark3 = 0\n",
    "    for j in range(xg.shape[0]):\n",
    "        for k in range(xg.shape[1]):\n",
    "            fourth_dik = np.sqrt((xob[i]-xg[j,k])**2+(yob[i]-yg[j,k])**2)\n",
    "            fourth_weight = cressman_weight(fourth_dik,R3)\n",
    "            weight_fark3 += fourth_weight*third_pass[j,k]\n",
    "            fourth_denom += fourth_weight\n",
    "        if fourth_denom > 0:\n",
    "            rev_cressman3[i] = weight_fark3/fourth_denom\n",
    "        else:\n",
    "            rev_cressman3[i] = np.nan\n",
    "    if bilinear3[i] > 0:\n",
    "        third_analysis[i] = bilinear3[i]\n",
    "    else:\n",
    "        third_analysis[i] = rev_cressman3[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d5d9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate Analysis Differences\n",
    "diff_21 = second_pass - first_pass\n",
    "diff_31 = third_pass - first_pass\n",
    "diff_32 = third_pass - second_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd006b7-12b7-4169-83b5-c05fe969b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate RMS \n",
    "diff1 = (GeoHeight - first_analysis)**2\n",
    "diff1 = diff1[~np.isnan(diff1)]\n",
    "rms1 = np.sqrt(np.sum(diff1/len(diff1)))\n",
    "\n",
    "diff2 = (GeoHeight - second_analysis)**2\n",
    "diff2 = diff2[~np.isnan(diff2)]\n",
    "rms2 = np.sqrt(np.sum(diff2/len(diff2)))\n",
    "\n",
    "diff3 = (GeoHeight - third_analysis)**2\n",
    "diff3 = diff3[~np.isnan(diff3)]\n",
    "rms3 = np.sqrt(np.sum(diff3/len(diff3)))\n",
    "\n",
    "print(rms1, rms2, rms3)\n",
    "## yes, I know something is wrong here\n",
    "rmsarray = np.array([rms1, rms2, rms3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c8ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot 500mb analyses over a map ###\n",
    "proj = ccrs.Stereographic(central_longitude=-115,central_latitude=90,true_scale_latitude=60)\n",
    "fig = plt.figure(figsize=(8,8),dpi=200)\n",
    "ax1 = fig.add_subplot(111,projection=proj)\n",
    "ax1.add_feature(cfeature.STATES, facecolor = 'lightyellow')\n",
    "ax1.add_feature(cfeature.COASTLINE)\n",
    "ax1.add_feature(cfeature.OCEAN, facecolor ='lightblue')\n",
    "\n",
    "#plot analysis (MAY NEED TO CHANGE VARIABLE NAMES/INDICES)#\n",
    "cs1 = ax1.contour(Lon_g,Lat_g,first_pass,colors='k',levels=np.arange(0,8000,60),transform=ccrs.PlateCarree())\n",
    "plt.clabel(cs1,levels=np.arange(0,8000,60))\n",
    "plt.title('Analysis Map (First Pass, 4cm)')\n",
    "plt.savefig(\"AnalysisFirstPass.png\", dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ed655-1e7a-4663-86da-a14e94106b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.Stereographic(central_longitude=-115,central_latitude=90,true_scale_latitude=60)\n",
    "fig = plt.figure(figsize=(8,8),dpi=200)\n",
    "ax1 = fig.add_subplot(111,projection=proj)\n",
    "ax1.add_feature(cfeature.STATES, facecolor = 'lightyellow')\n",
    "ax1.add_feature(cfeature.COASTLINE)\n",
    "ax1.add_feature(cfeature.OCEAN, facecolor ='lightblue')\n",
    "\n",
    "#plot analysis (MAY NEED TO CHANGE VARIABLE NAMES/INDICES)#\n",
    "cs1 = ax1.contour(Lon_g,Lat_g, second_pass, colors='k',levels=np.arange(0,8000,60),transform=ccrs.PlateCarree())\n",
    "plt.clabel(cs1,levels=np.arange(0,8000,60))\n",
    "plt.title('Analysis Map (Second Pass, 2.5cm)')\n",
    "plt.savefig(\"AnalysisSecondPass.png\", dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78983091-878b-4c6a-b36a-52d3d827e3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.Stereographic(central_longitude=-115,central_latitude=90,true_scale_latitude=60)\n",
    "fig = plt.figure(figsize=(8,8),dpi=200)\n",
    "ax1 = fig.add_subplot(111,projection=proj)\n",
    "ax1.add_feature(cfeature.STATES, facecolor = 'lightyellow')\n",
    "ax1.add_feature(cfeature.COASTLINE)\n",
    "ax1.add_feature(cfeature.OCEAN, facecolor ='lightblue')\n",
    "\n",
    "#plot analysis (MAY NEED TO CHANGE VARIABLE NAMES/INDICES)#\n",
    "cs1 = ax1.contour(Lon_g,Lat_g, third_pass, colors='k',levels=np.arange(0,8000,60),transform=ccrs.PlateCarree())\n",
    "plt.clabel(cs1,levels=np.arange(0,8000,60))\n",
    "plt.title('Analysis Map (Third Pass, 1.5cm)')\n",
    "plt.savefig(\"AnalysisThirdPass.png\", dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5de6f3-f1a9-4981-9e7c-38178eddf86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Analysis Differences ###\n",
    "proj = ccrs.Stereographic(central_longitude=-115,central_latitude=90,true_scale_latitude=60)\n",
    "fig = plt.figure(figsize=(8,8),dpi=200)\n",
    "ax1 = fig.add_subplot(111,projection=proj)\n",
    "ax1.add_feature(cfeature.STATES, facecolor = 'lightyellow')\n",
    "ax1.add_feature(cfeature.COASTLINE)\n",
    "ax1.add_feature(cfeature.OCEAN, facecolor ='lightblue')\n",
    " \n",
    "#plot analysis (MAY NEED TO CHANGE VARIABLE NAMES/INDICES)#\n",
    "cs1 = ax1.contour(Lon_g, Lat_g,diff_21[:,:],colors='k',levels = np.arange(-8000,8000,20),transform=ccrs.PlateCarree())\n",
    "plt.clabel(cs1,levels = np.arange(-8000,8000,20))\n",
    "plt.title('Analysis Difference(2nd & 1st Pass)')\n",
    "plt.savefig(\"AnalysisDiff21.png\", dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c9e2a-1d47-4711-aed3-18b7e95aa383",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.Stereographic(central_longitude=-115,central_latitude=90,true_scale_latitude=60)\n",
    "fig = plt.figure(figsize=(8,8),dpi=200)\n",
    "ax1 = fig.add_subplot(111,projection=proj)\n",
    "ax1.add_feature(cfeature.STATES, facecolor = 'lightyellow')\n",
    "ax1.add_feature(cfeature.COASTLINE)\n",
    "ax1.add_feature(cfeature.OCEAN, facecolor ='lightblue')\n",
    " \n",
    "#plot analysis (MAY NEED TO CHANGE VARIABLE NAMES/INDICES)#\n",
    "cs1 = ax1.contour(Lon_g, Lat_g,diff_31[:,:],colors='k',levels = np.arange(-8000,8000,20),transform=ccrs.PlateCarree())\n",
    "plt.clabel(cs1,levels = np.arange(-8000,8000,20))\n",
    "plt.title('Analysis Difference(3rd & 1st Pass)')\n",
    "plt.savefig(\"AnalysisDiff31.png\", dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767ecfd-6cce-44a2-bc84-e5d097a6d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.Stereographic(central_longitude=-115,central_latitude=90,true_scale_latitude=60)\n",
    "fig = plt.figure(figsize=(8,8),dpi=200)\n",
    "ax1 = fig.add_subplot(111,projection=proj)\n",
    "ax1.add_feature(cfeature.STATES, facecolor = 'lightyellow')\n",
    "ax1.add_feature(cfeature.COASTLINE)\n",
    "ax1.add_feature(cfeature.OCEAN, facecolor ='lightblue')\n",
    " \n",
    "#plot analysis (MAY NEED TO CHANGE VARIABLE NAMES/INDICES)#\n",
    "cs1 = ax1.contour(Lon_g, Lat_g,diff_32[:,:],colors='k',levels = np.arange(-8000,8000,20),transform=ccrs.PlateCarree())\n",
    "plt.clabel(cs1,levels = np.arange(-8000,8000,20))\n",
    "plt.title('Analysis Difference(3rd & 2nd Pass)')\n",
    "plt.savefig(\"AnalysisDiff32.png\", dpi = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store the analyses in text files ###\n",
    "file1_first = open(\"FirstPass\", \"w+\")\n",
    "file1_second = open(\"SecondPass\", \"w+\")\n",
    "file1_third = open(\"ThirdPass\", \"w+\")\n",
    "first_pass_txt = str(first_pass)\n",
    "second_pass_txt = str(second_pass)\n",
    "third_pass_txt = str(third_pass)\n",
    "file1_first.write(first_pass_txt)\n",
    "file1_second.write(second_pass_txt)\n",
    "file1_third.write(third_pass_txt)\n",
    "file1_first.close()\n",
    "file1_second.close()\n",
    "file1_third.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e29b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store the difference fields in text files ###\n",
    "file1_diff21 = open(\"Diff21\", \"w+\")\n",
    "file1_diff31 = open(\"Diff31\", \"w+\")\n",
    "file1_diff32 = open(\"Diff32\", \"w+\")\n",
    "diff21_txt = str(diff_21)\n",
    "diff31_txt = str(diff_31)\n",
    "diff32_txt = str(diff_31)\n",
    "file1_diff21.write(diff21_txt)\n",
    "file1_diff31.write(diff31_txt)\n",
    "file1_diff31.write(diff31_txt)\n",
    "file1_diff21.close()\n",
    "file1_diff31.close()\n",
    "file1_diff32.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc488357",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store RMS values in text file ###\n",
    "file1_rms = open(\"RMSOutput\", \"w+\")\n",
    "rms_txt = str(rmsarray)\n",
    "file1_rms.write(rms_txt)\n",
    "file1_rms.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c6680",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In a separte text file (or below), answer the following questions ###\n",
    "'''\n",
    "1 - Describe the general features that you see in your contoured analyses.\n",
    "Similar to the function fitting assignment, we see a trough over the western US, and a ridging pattern over the eastern US. \n",
    "\n",
    "2 - Describe the differences that you see in your contoured analyses.  \n",
    "    Does one analysis seem to be smoother than the other?  If so, what would cause this?\n",
    "The first pass is the smoothest of the three passes. Interestingly, the trough seems to become more outlandish and pointed/deep, while the ridging pattern\n",
    "seems to flatten a bit. Additionally, the height gradients become more pronounced with more corrections. \n",
    "This is likely because the the initial pass is just representative of the observations fit to the grid, while the second and third passes introduce\n",
    "corrections and the background becomes too similar to the observations. \n",
    "    \n",
    "3 - What happens as you increase the number of successive correction passes?  Is this \n",
    "    desirable?  Why or why not?\n",
    "As mentioned in question 2, increasing the successive correction passes makes the background more similar to the observations, which could be good and bad. \n",
    "If the observations are good, this could be good for seeing smaller scale, more local features. However, if you want to evaluate larger scale features this\n",
    "wouldn't really be desirable, or if the observations aren't good, then having the background heavily influence by observations with more passses would make \n",
    "for a bad analysis. \n",
    "    \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atsc528] *",
   "language": "python",
   "name": "conda-env-atsc528-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
